{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "course2.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNHAYYwLfOyMrpQWpcdJT02",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gaetan-landreau/meero_course_deep_learning/blob/master/course2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Course 2: Rooms classification task in Deep Learning.\n",
        "\n",
        "\n",
        "This notebook intends to give all the ressources required to perform a 11-classes room classification, based on Meero Real-Estate images.\n",
        "\n",
        "From a broad perspective, such task is first adressed through a Multi-Layers Perceptron. Considering one step beyond, we will build a Convolution Neural Network and train it on the same dataset to except training for a classification purpose.*\n",
        "\n",
        "Dataset used is still the RES one and is therefore made of 11 classes.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "SUWGSG1pcWDu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup\n",
        "\n",
        "Few core steps before delving into ML/DL code ☺️"
      ],
      "metadata": {
        "id": "uDriH-8JOhpB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Code dependencies. "
      ],
      "metadata": {
        "id": "9cu_L7vrPQBw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Install some librairies.\n",
        "!pip install opencv-python numpy torch torchvision "
      ],
      "metadata": {
        "id": "k2yNLzeqZhd3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Make sure the GPU is visible. \n",
        "import torch \n",
        "\n",
        "is_gpu_visible = torch.cuda.is_available()\n",
        "print(f'Is the GPU visible by Torch: {is_gpu_visible}')"
      ],
      "metadata": {
        "id": "pAAshdc7QGax",
        "outputId": "ca10506b-b93d-4256-b731-4eb2545f811b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Is the GPU visible by Torch: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mount Drive Volume \n",
        "\n",
        "*Required to get a direct access to the data we are going to use.*"
      ],
      "metadata": {
        "id": "zouWSCQyQo9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "edIjwdenkheS",
        "outputId": "efb4e36b-89c3-49cd-ae5f-18a2e559b1cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CNN training\n",
        "\n",
        "From a general perspective, the strategy can be summarized through: \n",
        "\n",
        "\n",
        "1. Build up a `DataLoader` to fed our network with some *(image,label)* data\n",
        "2. Create our `CNN architecture`\n",
        "3. Define the `loss` to optimize\n",
        "4. `Train` the network\n",
        "5. Save our `trained model` \n",
        "\n"
      ],
      "metadata": {
        "id": "I9tRfP9JUCyJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Data\n",
        "\n",
        "In this first section, our main goal is to define a class that is going to manage the way our network is fed with the data we have. \n",
        "\n",
        "It exists several ways of building such data pipeline. We are going to use one of the most straightforward solution and work with already packed data: \n",
        "\n",
        "- *X.npy* contains all our images. \n",
        "- *Y.npy* gathers the associated room labels. \n",
        "\n",
        "\n",
        "Core steps we need to make: \n",
        "\n",
        "- [ ] Define the preprocessing operations to apply.\n",
        "- [ ] Load these two files. \n",
        "- [ ] Make the `_getitem_()` method to define the way batch are going to be created. \n",
        "- [ ] Test our DataLoader to make sure everything run as it should !"
      ],
      "metadata": {
        "id": "4tZ9LLeecVcY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.transforms as T\n",
        "\n",
        "def transform_fn() -> dict:\n",
        "  \"\"\"\n",
        "  Such function defines the preprocessing pipeline that must be applied to an image, both \n",
        "  for the training and testing ones. All the operations are sequentially applied. \n",
        "\n",
        "  Args: None\n",
        "  Returns: [dict] - A dictionnary that contains two T.Compose() preprocessing pipeline.\n",
        "  \n",
        "  \"\"\"\n",
        "  transform = {\n",
        "        \"train\": T.Compose(\n",
        "            [\n",
        "                T.ToPILImage(),  # 1. Convert the np.array into a PIL image (internal requirement)\n",
        "                T.Resize((256, 256)), # 2. Resize the image to (256,256), no matter the original input size.\n",
        "                T.RandomHorizontalFlip(p=0.5),  # 3. With a probability p=0.5, flip horizontaly the image.\n",
        "                T.ToTensor(), # 4. Convert the image into a 3D tensor (H,W,C)\n",
        "                T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), # 5. Normalize the image.\n",
        "            ]\n",
        "        ),\n",
        "        \"test\": T.Compose(\n",
        "            [\n",
        "                T.ToPILImage(),\n",
        "                T.Resize((256, 256)),\n",
        "                T.ToTensor(),\n",
        "                T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "            ]\n",
        "        ),\n",
        "    }\n",
        "\n",
        "  return transform"
      ],
      "metadata": {
        "id": "4mCVNCEd2OsU"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset \n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "class MeeroRoomsDataset(Dataset):\n",
        "  \"\"\"\n",
        "  Main DataLoader class to perform rooms classification.\n",
        "  \"\"\"\n",
        "  LIST_ROOMS = ['bathroom', 'bedroom', 'building', 'diningroom',\\\n",
        "                'emptyroom', 'entrance', 'house', 'kitchen', \\\n",
        "                'livingroom', 'terrace', 'yard']\n",
        "  def __init__(self, indir: str, is_train: bool, transform):\n",
        "\n",
        "    # Input directory where all the images are stored.\n",
        "    self.indir = indir\n",
        "\n",
        "    # Set the flag to know if we are training or testing.\n",
        "    self.is_train = is_train\n",
        "\n",
        "    # Transformation pipeline for image preprocessing.\n",
        "    self.transform = transform\n",
        "\n",
        "    # Load the images and their corresponding labels.\n",
        "    if self.is_train:\n",
        "      self.load_train_dataset()\n",
        "    else: \n",
        "      self.load_test_dataset()\n",
        "\n",
        "\n",
        "  def __len__(self) -> int:\n",
        "    \"\"\" \n",
        "    Required to define the total length of the dataset.\n",
        "\n",
        "    Returns: \n",
        "      - The total number of elements we have in our dataset.\n",
        "    \"\"\"\n",
        "    return self.X.shape[0]\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    \"\"\"\n",
        "    Required method, used to define a single the data we need to access for training.\n",
        "\n",
        "    Returns : \n",
        "      - img ([np.array]): the preprocessed source image. \n",
        "      - label ([np.array]): The associated label.\n",
        "    \"\"\"\n",
        "    img, label = self.X[index], self.Y[index]\n",
        "    \n",
        "    ######################################################\n",
        "    ### To do: \n",
        "\n",
        "    # - Perform the pre-processing on the image\n",
        "    # - Return both the image and its corresponding label\n",
        "    ######################################################\n",
        "\n",
        "\n",
        "  def load_train_dataset(self):\n",
        "    \"\"\"\n",
        "    This function primarely intends to load the .npy files.\n",
        "\n",
        "    We want to define two attributes: \n",
        "      X ([np.array]) - The whole training images set.\n",
        "      Y ([np.array]) - The labels associated to each image from the training set.\n",
        "    \"\"\"\n",
        "    ########################################\n",
        "    ### To do: \n",
        "\n",
        "    # - Create the paths where the .npy are\n",
        "    # - Load the data accordingly\n",
        "    ########################################\n",
        "\n",
        "  def load_test_dataset(self):\n",
        "      \"\"\"\n",
        "      This function primarely intends to load the .npy files.\n",
        "\n",
        "      We want to define two attributes: \n",
        "        X ([np.array]) - The whole testing images set.\n",
        "        Y ([np.array]) - The labels associated to each image from the testing set.\n",
        "      \"\"\"\n",
        "      ########################################\n",
        "      ### To do: \n",
        "\n",
        "      # - Create the paths where the .npy are\n",
        "      # - Load the data accordingly\n",
        "      ########################################"
      ],
      "metadata": {
        "id": "a-xvxvHxULoT"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Test our Dataset class\n",
        "\n",
        "# Create our preprocessing pipeline.\n",
        "preprocessing_transform = transform_fn()\n",
        "\n",
        "# Instantiate an MeeroRoomsDataset object..\n",
        "dataset = MeeroRoomsDataset(indir = '',is_train = True,transform=preprocessing_transform['train'])\n",
        "\n",
        "# Get a single pair of (img,label)\n",
        "img, label = dataset[0]   # internally called the _getitem_ method(). \n",
        "\n",
        "## Ensure image and its label are consistents. \n",
        "# To get the corresponding room name. \n",
        "label_name = dataset.LIST_ROOMS[label] \n",
        "\n",
        "# Plot the image and make sure the corresponding label we have is correct.\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize = (10,10))\n",
        "plt.imshow(img.numpy()) # .numpy() since img is a [torch.Tensor] type after the preprocessing operation.\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SHHqkBBo12KR",
        "outputId": "489d76aa-d591-4f4f-91df-5d70782f8bf2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-6c3dd3ef18aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLIST_ROOMS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;31m# Get a single pair of (img,label)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m#img, label = dataset[0]   # internally called the _getitem_ method().\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: 4 is not in list"
          ]
        }
      ]
    }
  ]
}